\documentclass[cyan,normal,en]{elegantnote}

\title{Computer Graphic Note}
\author{Jiechang Shi}
\version{1.1}
\date{\today}

\begin{document}

\maketitle

\section{Class 1: Overview}
\begin{enumerate}
	\item Frame Buffer
	\begin{itemize}
		\item Pixel: One element of a frame buffer
		\item Pixel depth: Number of bytes per-pixel in the buffer
		\item Resolution: Width $\times$ Height
		\item Buffer size: Total memory allocated for frame buffer
		\item \textbf{Exam Question}: Given Resolution and Pixel depth, Asked Buffer size
		\item Z Value: For solving the hidden-surface removal(HSR) problem
	\end{itemize}
\end{enumerate}
\newpage
\section{Class 2,3: Rasterization}
\begin{enumerate}
	\item For each pixel on screen, the sample point of that pixel is the center point of that pixel, which have \textbf{integer} coordinates. For examples, $(3,2)$.
	\item A simple problem: Rasterizing Lines \\
	\textbf{Program Description}: Given two endpoints, $P = (x_0,y_0)$ , $R=(x_1,y_1)$ find the pixels that make up the line. \\
	\textbf{Note that}: Lines are infinitely thin so they rarely fall on pixel sample point.\\
	\textbf{A Feasible Description}: Rasterize lines as \textbf{closest} pixels to actual lines, with 2 requirement
	\begin{itemize}
		\item No Gap
		\item Minimize error(distance to true line)
	\end{itemize}
	\textbf{To make this question simplify}: Only consider situation that $|x_1 - x_0| \geq |y_1 - y_0| \geq 0 \land |x_1-x_0| \neq 0$, which means the $-1 \leq slope \leq 1$. Otherwise we just exchange $x$ and $y$. \\
	\textbf{A basic Algorithm}: $k=\frac{y_1-y_0}{x_1-x_0}$, $d=y_0-kx_0$, for each $x_0 \leq x \leq x_1$, $y=ROUND(kx+d)$. This method by brute force is inefficient because of the multiplication and the function $ROUND()$.\\
	\textbf{Basic Incremental Algorithm}: for each $x_0 \leq x_i < x_{i+1} \leq x_1$, $y_{i+1} = y_i +k$, However, the successsive addition of a real number can lead to a \textbf{cumulative error buildup}!\\
	\textbf{Midpoint Line Algorithm}: 
	\begin{itemize}
		\item For $0 \leq k \leq 1$
		\item For one approximate point $P=(x,y)$, we only have 2 choices for the next point $E=(x+1,y)$ and $NE=(x+1,y+1)$, we should choose the one which is closer to $k(x+1)+d$
		\item Calculate the middle point $M=(x+1,y+\frac{1}{2})$
		\item If the \textbf{Intersection point} $Q$ is below $M$, take $E$ as next, otherwise take $NE$ as next.
		\item Note that: we consider this equation:
		$$ f(x,y)=ax+by+c=(y_1-y_0)x - (x_1-x_0)y + (x_1y_0-y_1x_0)$$
		We assume $a>0$
		\item For a point $(x,y)$\\
		if $f(x,y)=0$, $(x,y)$ lies on the line.\\
		if $f(x,y)<0$, $(x,y)$ lies upon the line.\\
		if $f(x,y)>0$, $(x,y)$ lies below the line.
		\item So we have to test $f(M)=a(x+1)+b(y+\frac{1}{2})+c=f(Former)+a+\frac{b}{2}$
		\item Assum $a>0$, if $f(M) > 0$ choose $NE$ otherwise choose $E$
		\item Update $f(Former)$:\\
		If we choose $E$, $f(Former)=f(Former)+a$\\
		If we choose $NE$, $f(Former)=f(Former)+a+b$\\
		Note that:$a$ and $b$ are \textbf{constant integer}, so here is no \textbf{cumulative error issuse}
	\end{itemize}
	\item A harder problem: Triangles Rasterization\\
	\textbf{Why Triangle}:
	\begin{itemize}
		\item Triangles (\textit{tris}) are a simple explicit 3D surface representation.
		\item Convex and concave polygons (\textit{polys}) can be decomposed into triangles.
		\item Tris are planar and unambiguously defined by three vertex(\textit{verts}) coordinates (\textit{coords}).
	\end{itemize}
	\textbf{Definition}: Find and draw \textbf{pixel} samples \textbf{inside} \textit{tri} edges and interpolate parameters defined at \textit{verts}
	\item \textbf{Rasterizxation and Hidden Surface Removal(HSR) Algorithm Classes}:
	\begin{itemize}
		\item Image order rasterization: ray tracing/ ray casting \\
		\underline{traverse} pixel, process each in world-space\\
		\underline{transform} rays from image-space to world-space
		\item Object order rasterization: scan-line / LEE \\
		\underline{traverse} triangles, process each in image-space\\
		\underline{transform} objects from model-space to image-space
	\end{itemize}
	\item \textbf{LEE Linear Expression Evaluation Algorithm}:
	\begin{itemize}
		\item We already discussed in \textit{Midpoint Line Algorithm} that how to determine a point is on the left(up) or right(below) the line, just \textit{a quick review here}:\\
		Assume the lien have a positive $slope$\\
		For an Edge Equation $E$, for point $(x,y)$: $E(x,y)=dY(x-X)-dX(y-Y)$\\
		if $E(x,y)=0$, $(x,y)$ lies on the line.\\
		if $E(x,y)<0$, $(x,y)$ lies right(below) the line.\\
		if $E(x,y)>0$, $(x,y)$ lies left(up) the line.
		\item For \textbf{Rasterization}:\\
		Compute LEE result for all three edges.\\
		Pixels with \textbf{consistent sign} for all three edges are inside the \textit{tri}.\\
		Include \textbf{edge pixels} on left or right edges.
		\item LEE need to check every pixel in the bounding box.
		\item LEE is very good in parallel(SIMD) system.
		\item Furthermore: Given 3 random \textit{verts} how to find CW edge cycle\\
		Determine L/R and Top/Bot edges for edge-pixel ownership
	\end{itemize}
	\item \textbf{Scan Line Rasterizer}:
	\begin{itemize}
		\item Sort vets by Y
		\item Setup edge DDAs for edges
		\item Sort edges by L or R(The long edge on left or right)
		\item Start from Top Vertice, and switch DDA when hit the middle vertice.		
	\end{itemize}
	\item \textbf{Interpolate Z}:\\
	A general 3D plane equation has 4 terms: $Ax+By+Cz+D=0$\\
	$(A,B,C)$ is the normal of that plane, so $(X,Y,Z)_0 \times (X,Y,Z)_1 = (A,B,C)$\\
	Then plug any vertex coord into equation and solve for $D$.\\
	Given $(A,B,C,D)$ and any point $(x,y)$ can solve $z$
	\item \textbf{Used $Z$-buffer to remove hidden surfaces}\\
	Initial $Z$-buffer to MAXINT at the begining of every frame\\
	Interpolate vertex $Z$ values to get $Z_{pix}$\\
	Only write new pixel to the buffer if $Z_{pix}<Z_{buffer}$\\
	Notice that $Z$ should always \textbf{bigger or equal to zero!}
	\item Hidden Line Removal(HLR):\\
	Simple z-buffer does not work when the render only draws edge(outlines of polygons).\\
	Need edge-crossing and object sorting methods.
	\item \textbf{Painter's Algorithm}: render in order front to back\\
	A object is in front of another object means:\\
	Z of all verts of one object is less than the other.\\
	This algorithm not work if Z-sort is ambiguous.
	\item \textbf{Warnock Algorithm}:\\
	Subdivide screen untril a leaf region has a simple front/back relationship.\\
	Leaf regions have one or zero surfaces visible, and the smallest region is usually a pixel\\
	Usually use quad tree subdivision
	\item \textbf{BSP-Tree}:\\
	View-Independent binary tree(pre-calculated) allows a view-dependent front-to-back or back-to-front traversal of surfaces.\\
	Use Painter Algorithm to do back-to-front traversal.\\
	Useful for \textbf{transparency} - full depth-sort of all surface.
	\item \textbf{Culling}:
	\begin{itemize}
		\item Culling with portals: pre-compute the invisible part.
		\item Culling by View Frustum: Skip a triangle iff all its vertices are beyond \textbf{the same screen edge}!\\
		\textbf{Pitfall:} If the vertices are beyond different edge, some part of the \textit{tri} might still in the screen. Image a giant \textit{tri} that cover the whole screen.
		\item Backface Culling: For \textbf{closed(water-tight)} objects, surfaces with \textbf{oriented-normals facing away} from the camera are never visible.\\
		\textbf{Pitfall}: BF Culling only work for water-tight object!
		\item Frustum: Only visible triangles are drawn into the frame buffer.
	\end{itemize}
\end{enumerate}
\newpage
\section{Class 4,5,6,7:Transformations}
\begin{itemize}
	\item Linear transformations (\textit{Xforms}) define a mapping of coordinates (\textit{coords}) in one coordinate frame to another.
	$$V_b=X_{ba}V_a$$
	\item \textbf{Homogeneous Vector} ($V$) is $4\times 1$ columns $(x,y,z,w)^T$
	\item \textbf{Homogeneous Transforms} ($X$) is $4 \times 4$ matrix
	\item From Homogeneous Vector to 3D Vector:
	$$x=\frac{x}{w} , y=\frac{y}{w},z=\frac{z}{w}$$
	\item \textbf{Why} we use Homogeneous Vector?\\
	We want to uniform the transform matrix including translation, scaling, rotation in the same form of matrix.
\end{itemize}
\subsection{Transformation Matrix}
\begin{enumerate}
	\item \textbf{Translation}:
	$$T(t_x,t_y,t_z)\Rightarrow 
	\begin{bmatrix}
	1 & 0 & 0 & t_x \\
	0 & 1 & 0 & t_y \\
	0 & 0 & 1 & t_z \\
	0 & 0 & 0 & 1
	\end{bmatrix},
	T^{-1}(t_x,t_y,t_z)=T(-t_x,-t_y,-t_z)
	$$
	\item \textbf{Scaling}:
	$$S(s_x,s_y,s_z)\Rightarrow 
	\begin{bmatrix}
	s_x & 0 & 0 & 0 \\
	0 & s_y & 0 & 0 \\
	0 & 0 & s_z & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix},
	S^{-1}(s_x,s_y,s_z)=S(\frac{1}{s_x},\frac{1}{s_y},\frac{1}{s_z})
	$$
	\item \textbf{Rotation, CCW}:
	$$R_x(\theta)\Rightarrow 
	\begin{bmatrix}
	1 & 0 & 0 & 0 \\
	0 & cos\theta & -sin\theta & 0 \\
	0 & sin\theta & cos\theta & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix},
	R^{-1}_x(\theta)=R^T_x(\theta)
	$$
	$$R_y(\theta)\Rightarrow 
	\begin{bmatrix}
	cos\theta & 0 & sin\theta & 0 \\
	0 & 1 & 0 & 0 \\
	-sin\theta & 0 & cos\theta & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix},
	R^{-1}_y(\theta)=R^T_y(\theta)
	$$
	$$R_z(\theta)\Rightarrow 
	\begin{bmatrix}
	cos\theta & -sin\theta & 0 & 0 \\
	sin\theta & cos\theta & 0 & 0 \\
	0 & 0 & 1 & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix},
	R^{-1}_z(\theta)=R^T_z(\theta)
	$$
	\item Pitfall: \underline{commutative} property is for S,R only.\\
	Here assume \textbf{uniform scaling} in all dimensions. \\
	If S is not an uniform scaling matrix. S,R don't have commutative property.
\end{enumerate}
\subsection{Spaces Transformation}
\begin{enumerate}
	\item \textbf{NDC to Output Device}
	$$X_{sp}\Rightarrow 
	\begin{bmatrix}
	\frac{xs}{2} & 0 & 0 & \frac{xs}{2} \\
	0 & -\frac{ys}{2} & 0 & \frac{ys}{2} \\
	0 & 0 & MAXINT & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix}
	$$
	Note that:\\
	Output Device is \textbf{RH coords} and origin in \textbf{upper left}.$X\in [0,xs), Y\in [0,ys), Z\in [0,MAXINT]$\\
	NDC is \textbf{LH coords} and origin at screen center. $X,Y \in [-1,1],Z \in[0,1]$
	\item \textbf{Perspective Projection}
	$$X_{pi}\Rightarrow 
	\begin{bmatrix}
	1 & 0 & 0 & 0 \\
	0 & 1 & 0 & 0 \\
	0 & 0 & \frac{1}{d} & 0 \\
	0 & 0 & \frac{1}{d} & 1
	\end{bmatrix}
	$$
	\textbf{What} is $d$ And \textbf{Why} there are two \textbf{$\frac{1}{d}$}?
	\begin{itemize}
		\item Assume camera is on $(0,0,-d)$, perspective(also image) plane is $z=0$, a object in world space is $(X,Y,Z)$
		\item Defined FOV(field of view) as the angle the camera can see.
		\item Note: $X\in [-1,1]$, so the distant($d$) from Forcus point to view plane can be calculate by this equation:
		$$\frac{1}{d}=tan(\frac{FOV}{2})$$
		\item Futher More: The object project to view plane can be calculate by these equations:
		$$\frac{X}{Z+d}=\frac{x}{d} \Rightarrow x=\frac{X}{\frac{Z}{d}+1}$$
		$$\frac{Y}{Z+d}=\frac{y}{d} \Rightarrow y=\frac{Y}{\frac{Z}{d}+1}$$
		$$\frac{Z}{Z+d}=\frac{z}{d} \Rightarrow z=\frac{Z}{\frac{Z}{d}+1}$$
		$$(x,y,z)=(\frac{X}{\frac{Z}{d}+1},\frac{Y}{\frac{Z}{d}+1},\frac{Z}{\frac{Z}{d}+1})$$
		\item Write this 3D vector to Homogeneous Vector:
		$$(x,y,z,w)=(X,Y,Z,\frac{Z}{d}+1)$$
		\item Futher: We forcus on the \textbf{range} of Z now is $z\in (-\infty,d)$.\\
		But in NDC we hope $z \in [0,1)$ So:\\
		We delete all vector that $Z<0$, because they cannot project to the view plane.\\
		For $z>=0$, we define $z'=\frac{z}{d}$
		\item $(x,y,z',w)=(X,Y,\frac{Z}{d},\frac{Z}{d}+1)=X_{pi}*(X,Y,Z,1)$
	\end{itemize}
	\textbf{Pitfall}: \textbf{Do Z interpolation in Perspective Plane!}\\
	\textbf{Why} we need the farest plane?\\
	Asymptotic curve of $Z$ $vs.$ $z$, that z increase slower when Z is large.\\
	It might map different $Z$ to the same $z$
\end{enumerate}
\subsection{Camera Matrix}
\begin{enumerate}
	\item Assume camera position is $c$, camera look-at point is $l$, here $c$ and $l$ are both in world coordinate. And the world up vector is $\vec{up}$
	\item Camera Z-axis \textbf{in world coordinate} is $$\vec{Z}=\frac{\vec{cl}}{||\vec{cl}||}$$
	\item Camera Y-axis \textbf{in world coordinate} is the orthogonal(vertical) part of world-up vector to Z-axis which is $$\vec{up'}=\vec{up}-(\vec{up}\cdot \vec{Z})\vec{Z}$$
	$$\vec{Y}=\frac{\vec{up'}}{||\vec{up'}||}$$
	\item Camera X-axis \textbf{in world coordinate} is orthogonal to both Y and Z axises. So:
	$$\vec{X}=\vec{Y}\times\vec{Z}$$
	\item Build the $X_{wi}$ from camera space to world space:\\
	X-axis vector $[1,0,0]$ in camera space should be $\vec{X}$ in world space, also for Y,Z-axis vectors, So:
	$$X_{wi}\Rightarrow 
	\begin{bmatrix}
	X_x & Y_x & Z_x & 0 \\
	X_y & Y_y & Z_y & 0 \\
	X_z & Y_z & Z_z & 0 \\
	0 & 0 & 0 & 1
	\end{bmatrix}
	$$
	\item Also we need to add the translation of the camera to the Matrix:
	$$X_{wi}\Rightarrow 
	\begin{bmatrix}
	X_x & Y_x & Z_x & c_x \\
	X_y & Y_y & Z_y & c_y \\
	X_z & Y_z & Z_z & c_z \\
	0 & 0 & 0 & 1
	\end{bmatrix}
	$$
	\item Now we can get the inverst matrix $X_{iw}$:
	$$X_{iw}\Rightarrow 
	\begin{bmatrix}
	X_x & X_y & X_z & -X\cdot c \\
	Y_x & Y_y & Y_z & -Y\cdot c \\
	Z_x & Z_y & Z_z & -Z\cdot c \\
	0 & 0 & 0 & 1
	\end{bmatrix}
	$$
	\item In this proof we know that: If we know the X,Y,Z-axis in world coordinate for a specific space, we can easily build and inverst the translation from or to that space.\\
	This method can also be used to \textbf{proof the general rotation matrix}. 
	\item Orbit a Model about a Point\\
	The idea is the same as place camera.\\
	Need to care about \textbf{which space} you current in!
\end{enumerate}
\newpage

\section{Class8-10 Illumination and Shading}
\begin{enumerate}
	\item Global vs. Local Illumination\\
	Global: Models indirect illumination and occlusions
	Local: Only models direct illumination
	\item Irradiance
	$$E=\int_{\Omega} I(x,\omega) cos \theta dx$$
	Note: $I(x,\omega)$ is the light intensity arriving from all directions and entering the hemisphere $\Omega$ over unit serface area.\\
	Also we only care the vertical(normal) part of the light, we dismiss all lights parallel to the surface by using $\cos \theta$
	\item Simplified lighting:\\
	Assume all lights are distant-point light.
	\begin{itemize}
		\item Source have \textbf{uniform} intensity distribution
		\item Neglect distance fallout
		\item Direction to source is constant within scene
		\item Using 2 parameters to define a light:\\
		$direction(x,y,z)$ vector from surface to light source\\
		$intensity(r,g,b)$ of the light
	\end{itemize}
	\item specular reflection and diffuse reflection
	\begin{itemize}
		\item Color shift by attenuation of RPG components for all reflection
		\item Specular Reflection Model(View-Dependent):\\
		$$L_j(V) = L_e \cdot K_s \cdot (V\cdot R)^{spec}$$
		$$R=2(N\cdot L)N-L$$
		Note: $V$ and $R$ should be normalized.\\
		Direction: Reflection occurs mainly in the "mirror" R direction, but there is some spread in similar directions $V$.\\
		$spec$ controls the distribution of intensity about R. Higher value of $spec$ make the surface smoother\\
		$K_s$ controls the color attenuation of Surface.
		\item Diffuse Reflection Models(View-Independent):\\
		$$L_j = L_e \cdot K_d (L\cdot N)$$
		Direction: All \textbf{output} directions are the same. But we only care vertical \textbf{input} light.\\
		$L$ and $N$ should be normalized.\\
		$K_d$ is the surtface attenuation component.
		\item Ambient Light\\
		$$L_j = L_a \cdot K_a$$
		Direction: All input and output directions are the same.\\
		Only one ambient light is needed and allowed.
		\item Complete Shading Equation:
		$$Color=(K_s\sum{ L_e \cdot (V\cdot R)^{spec}}) + (K_d\sum{ L_e \cdot (L\cdot N)}) + (L_a \cdot K_a)$$	
	\end{itemize}
	\item Detail about HW4(Lighting Implementation)
	\begin{itemize}
		\item $\vec{L}$ denotes the direction to a infinity-far point-light source
		\item $\vec{E}$ denotes the camera direction. If camera is far away, $\vec{E}$ is constant(In HW4.)
		\item $\vec{N}$ is specified at triangle vertices.
		\item $\vec{R}$ must be computed for each lighting calculation (at \textbf{a point}).\\
		Calculation of $\vec{R}$:\\
		$$\vec{R}=2(\vec{N}\cdot \vec{L})\vec{N}-\vec{L}$$\\
		Avoiding sqrt-root in this calculation
		\item Choosing a Shading Space: Wee need all $\vec{L},\vec{E},\vec{N},\vec{R}$ in some affine(pre-perspective) space \\
		Suggest use \textbf{Image Space} for HW4. \\
		\textbf{Model space} is also a reasonable choice since Normal vectors are already in that space. This is most \textbf{efficient}!
		\item \textbf{Image Space Lighting (ISL)}\\
		Create a Transformation stack from model space to image space.\\
		Need to \textbf{normalized the Scale and delete translation} for each matrix, \textbf{only maintain the rotation}, before push into this stack!
		\item \textbf{Check} the sign of \textbf{$\vec{N}\cdot\vec{E}$} and \textbf{$\vec{N}\cdot\vec{L}$}:\\
		Both positive: Compute lighting model.\\
		Both negative: \textbf{Flip normal($\vec{N}$)} and compute lighting model.\\
		Different sign: Skip it.
		\item \textbf{Check} the sign of \textbf{$\vec{R}\cdot\vec{E}$}: If negative, set to 0.
		\item \textbf{Check} color overflow($>1.0$): Set to 1.
		\item \textbf{Compute Color} at all pixels:\\
		\textbf{Per Face} - flat shading\\
		\textbf{Per Vertex} - interpolate vertex colors, Gouraud Shading(specular highlights are undersampled, aliased).\\
		\textbf{Per Pixel} - interpolate normals, Phong Shading (Expensive computation, but better sampling)\\
		Set \textbf{Shading Modes Parameter} for different lighting calculation.
		\item \textbf{Pitfall} in \textbf{Phong} Interpolation:\\
		Need to \textbf{normalize} the interpolation normal vector.
	\end{itemize}
\end{enumerate}
\subsection{Class10: Something More About Shading}
\begin{enumerate}
	\item Non-Uniform Scaling: \\
	\textbf{A non-uniform scaling alters the relationship between the surface orientation and the Normal Vector.}\\
	So we \textbf{cannot} use the same matrix M for transformation of the Normals and the vertex coordinates.\\
	We can fix this by using a different transformation $Q=f(M)$ for transforming the Normals.
	\item How to create a matrix for Normals:\\
	In HW4, We create a matrix \textbf{dismiss all} scale matrix.\\
	For Detail:\\
	As the definition of Normals: 
	$$\vec{N}^T\cdot\vec{P}=0$$
	After include the transform matrix: 
	$$(Q\vec{N})^T\cdot(M\vec{P})=0$$
	By Definition of Matrix Multiplyer:
	$$\vec{N}^T \cdot Q^T \cdot M \cdot \vec{P}=0$$
	Since we already know $\vec{N}^T\cdot\vec{P}=0$ we only need the inner part equal to identity matrix:
	$$Q^T \cdot M= I,Q=(M^{-1})^T$$
	Note that: If we only used uniform scaling: $S=I$ after normalization.\\
	If we compute $Q$ for each $M$ pushed on the $X_{im}$ transform stack, the resulting $X_n$ stack has $Q$ and therefore allows non-uniform scaling.	
	\item Model Space Lighting(MSL): \\
	Only need to transform Global lighting parameters once per models.\\
	Also need to transform Eye/camera direction into model space.
\end{enumerate}
\newpage

\section{Class 11-13: Texture Mapping}
\subsection{Screen-Space Parameter Interpolation}
\begin{enumerate}
	\item In Z-buffer interpolation, we know that linear interpolation for $z$ is \textbf{wrong in image space}, we need to interpolate in \textbf{perspective space}.
	\item Accurate interpolation of RGB color or Normal vectors should also take perspective into account.\\
	But we can ignore the color and normal interpolation error.
	\item Interpolation for \textbf{Texture Function}: checkerboard Example: Using Linear Interpolation for $u\&v$ is also wrong!
	\item How to compute perspective-correct interpolation of $u,v$ at each pixel.
	\begin{itemize}
		\item For each parameter $P$, we used $P^s$ to denote the value in perspective space.
		\item Note that: For Z interpolation $V_z^s=\frac{V_z}{\frac{V_z}{d}+1}=\frac{V_z \cdot d}{V_z+d}$
		\item Rescale $V_z^s$ to $V_z^s \in [0,Z_{max}]$ 
		$$V_z^s=\frac{V_z \cdot d}{V_z+d} \cdot (\frac{Z_{max}}{d})=\frac{V_z \cdot Z_{max}}{V_z+d}$$
		\item We can also get the invert equation:
		$$V_z=\frac{V_z^s \cdot d}{Z_{max} - V_z^s}$$
		\item For parameter from image space to perspective space:
		$$P^s=\frac{P}{\frac{V_z}{d}+1}=\frac{Pd}{V_z+d}$$
		\item Also we can get inver equation:
		$$P=\frac{P^s(V_z+d)}{d}$$
		\item We don't have $V_z$ but we already calculated $V_z^s$ in HW2, so we can used that:
		$$P^s=\frac{P}{(\frac{V_z^s}{Z_{max} - V_z^s}+1)}$$
		$$P=P^s \cdot \frac{V_z^s}{Z_{max} - V_z^s}+1$$
		\item Note that we only have $V_z^s$ and $Z_{max}$ in this equation that we already know the value, we don't need to care $d$ and some other parameter.
		\item We used $V_z' = \frac{V_z^s}{Z_{max} - V_z^s}$ to simplify the equation:
		$$P^s=\frac{P}{V_z' +1}$$
		$$P=P^s \cdot(V_z'+1)$$
	\end{itemize}
	\item The Step for Parameter interpolation:\\
	Get $V_z^p$ for each vertex.\\
	Transform $P$ to perspective space $P^s$ for each vertex.\\
	Interpolate $V_z^p$ for each pixel.\\
	Interpolate $P^s$ for each pixel. \\
	Transform $P^z$ back to $P$ by using $V_z^p$ for each pixel.
\end{enumerate}
\newpage
\subsection{Texture}
\begin{enumerate}
	\item Scale $u,v$ to Texture Image Size:\\
	$(u,v)$ coords range over $[0,1]$\\
	2D Image is a pixel array of $xs-1,ys-1$\\
	But $u*(xs-1)$ might not be Integer so we need to interpolate the color for non-Integer $(u,v)$ coordinate from nearest 4 Integer point.
	$$Color(p)=(1-s)(1-t)A+s(1-t)B+stC+(1-s)tD$$
	\item For Phong Shading, using texture function $f(u,v)$ to replace $k_d$ and $k_a$
	\item For Gouraud Shading, using $f(u,v)$ to replace all $k_s$, $k_d$ and $k_a$
	\item Procedural Texture
	\item Bump Texture:
	\begin{itemize}
		\item Alter normals at each pixel to create bump.
		\item Normal Perturbation($\vec{P}$): $N'=N+P$, $\vec{P}$ should be in the same space as N. But $\vec{P}$ should not be in model space.
		\item Better spaces for $\vec{P}$ are Surface Coordinates, Tangent Space.
	\end{itemize}
	\item Surface Coordinates:
	\item Normal Space encodes the surface normal rather than perturbation.
	\item Noise Texture:
	\begin{itemize}
		\item Perlin Noise:(Ref(Chinese): \href{https://www.cnblogs.com/leoin2012/p/7218033.html}{https://www.cnblogs.com/leoin2012/p/7218033.html}
		\item Input: $(x,y,z)$ for 3D and $(u,v)$ in 2D
		\item Output: double value between 0 and 1
		\item We have 2 Pseudo Random Grid for each Integer Point(x,y,z are integers):
		\begin{itemize}
			\item Noise Matrix($d$): The color of Point for noise
			\item Gradient Matrix($g$): A random unit vector for each Point
		\end{itemize}
		\item For each input vector$(u,v)$, if $(u,v)$ isn't Integer, we found 4-corners Integer Point: $(i,j),(i+1,j),(i,j+1),(i+1,j+1)$
		\item For each Integer Point, we use \textbf{dot product} of distant vector(from $(u,v)$ to Integer Point) and gradient vector to get the noise value.
		\item In perlin noise every interpolation is in 1-D. So 2-D need first interpolate y-axis(twice) and then interpolate x-axis. 3-D need 7 interpolation.
		We used linear-interpolation in slides but we can use \textbf{Fade} function(easy curves) for better interpolation.
		\item Turbulence: Sum noise with diminishing ampitude:
		$$turbulence(x)=\sum_{k}^{i=0} \frac{1}{2^i}|noise(2^i x)|$$
	\end{itemize}
	\item Evironment(Reflection) Mapping:
	\begin{itemize}
		\item Basic Idea: During rendering, compute the reflection of Eye vector(not the light vector)
		\item \textbf{Ignore the position of surface point} in scene. We assume all points are on center point of the scene.
		\item Light and scenery are all merge into environment texture.
		\item No object inter-reflection or shadow
		\item Blur texture to simulate diffuse reflection
		\item Sharp texture to simulate specular reflection
	\end{itemize}
	\item Cube Map:
	\begin{itemize}
		\item Transform each Eye reflection vector R back to world space
		\item Find Max component: indicated which face of cube it would intersect
		\item Compute intersection of R with cube face:\\
		Move all Reflection ray tail to center of cube.
		Rescale the max component(for example$y$) of vector R to 1.0.\\
		The other 2 component($x,z$) indicate the texture-pixel.
	\end{itemize}
	\item Refraction Map:
	\begin{itemize}
		\item Use Snell's law to compute refraction vector
		\item Color aberration simulated with $f(\lambda)$ refraction angle for multiple color bands
	\end{itemize}
\end{enumerate}
\subsection{Implementation Of Texutre(HW5)}
\begin{enumerate}
	\item Step1: Texture coordinates: surface point $\rightarrow$ $(u,v)$\\
	Input: vertex in image space\\
	Output: $(u,v)$
	\item Step2: $(u,v)$ $\rightarrow$ RGB color\\
	Input: $(u,v)$
	Output: RGB color from image LUT
	\item Interpolation of $(u,v)$ need to be in perspective space.
	\item Interpolation of 4-corner for non-Integer $(u,v)$ is needed.
\end{enumerate}
\newpage

\section{Class14-16 Antialiasing}
\subsection{The Source of Aliasing}
\begin{enumerate}
	\item Quantization error arise from insufficient accuracy of sample
	\item Aliasing error arise from insufficient samples
	\item Nyquist Theorem: Sample at least twice the rate of highest frequency present in the signal.\\
	f(t) filtered for cutoff freq $\omega_F$(Remove high frequencies before sampling)\\
	Sample Rate $\frac{1}{T_0}$ is greater than $2\omega_F$\\
	Reconsturct(interpolate) with $sinc$ function
	\item Solution: Band-limit the input signal before sampling.
\end{enumerate}
\subsection{Implement Antialiasing(HW6)}
\begin{enumerate}
	\item Antialiasing by jitter supersampling
	\item Sample a pixel several with different center and weight
\end{enumerate}
\subsection{Texture Antialiasing}
\begin{enumerate}
	\item Sample Rate Mismatch: Texture sampling rate generally does not match screen pixel sample rate (Texel:Pixel ratio)
	\item Projected texture in screen image should sample near same rate(1:1) to texture map.\\
	1 Texel: Many Pixel: No aliasing problem, But blur. Fix by using higher resolution textures.\\
	1 Pixel: Many Texel: Aliasing problem. Fix by sample rate is twice highest freq in texture.
	\item Mip Map: Pre-compute filtered version of texture image at octave scale/size intervals.\\
	Using average color of $2 \times 2$ texels.\\
	The space cost is only $33\%$ more.\\
	Scale for each level of Mip Map:
	$$Scale=\frac{dU}{dX}=\frac{dV}{dY}$$
	Pixel Scale is more complex since it is non-axis-aligned(after rotation and projection):
	$$PixelScale=(\frac{dU}{dX},\frac{dU}{dY},\frac{dV}{dX},\frac{dV}{dY})$$
	An approach to match Scale and PixelScale is choosing the highest PixelScale component.(Blur is better than aliasing!)
	\item 3D Interpolation: If the Pixel Scale is between 2 Texel Scales, we need to interpolate between 2 texture samples.
	\item Anisotropic Interpolation: Combine more than $2 \times 2$ pixel in each texture samples.
	\item Summed-Area Table(SAT):Compute a texture table T so that each texel has sum of \textbf{all texels above and left}\\
	SAT provide an approximation approach to get the avagerage color in O(1).\\
	Note that: the texels sample might not be axis-aligned since	 the pixel to texel projection. But the different is strictly less than $\frac{1}{2}$.
\end{enumerate}
\newpage

\section{Final Exam Review}
\begin{enumerate}
	\item Shading Equation:
	$$Color=(K_s\sum{ L_e \cdot (E\cdot R)^{spec}}) + (K_d\sum{ L_e \cdot (L\cdot N)}) + (L_a \cdot K_a)$$
	Know the meaning for every terms:
	\begin{itemize}
		\item $K_s,K_a,K_d$
		\item $L_e,L_a$
		\item $s$
		\item $N,L,R,E$
		\item Equation1: $R=2(N\cdot L) N-L$
	\end{itemize}
	\item Shading Mode:(Flat, Gouraud, Phong)
	\item Texture
	\item Calculate the normal: With Non-translate and Non-scale Matrix To Image Space
	\item Other Topic:
	\begin{itemize}
		\item Enviroment Shading 
	\end{itemize}
\end{enumerate}
\newpage

\section{BRDF}

Reference for this section(In Chinese): \href{https://blog.csdn.net/yjr3426619/article/details/81098626}{https://blog.csdn.net/yjr3426619/article/details/81098626}
\subsection{What is BRDF}
\begin{itemize}
	\item Basic Idea of BRDF: The reflect rate for a surface is based on input vector and camera vector.
	$$f(l,v)=\frac{dL_0(v)}{dE}(ForNonPointLight)=\frac{L_o(v)}{E_L cos\theta_i}(ForPointLight)$$
	\begin{itemize}
		\item $l$: input light vector
		\item $v$: camera vector
		\item $L_0$: Output Radiance(Color)
		\item $E_l$: Input Irradiance(Color*$\pi$ in Unity)
		\item $\theta_i$: angle between input vector and surface normal
	\end{itemize}
	\item Properties of $f(l,v)$
	\begin{itemize}
		\item $f(l,v)\geq 0$
		\item $f(l,v)=f(v,l)$
		\item $R(l)=\int_\phi f(l,v) cos\theta_0 d\omega \leq 1$, Discussed later
	\end{itemize}
	\item How to calculate color based on BRDF:
	\begin{itemize}
		\item In Point Light, Point Camera:
		$$L_0(v)=\sum_k f(l_k)\times E_l cos\theta_{ik}$$
	\end{itemize}
	\item Directional-hemispherical reflectance:
	\begin{itemize}
		\item Definition:
		$$R(l)=\int_\phi f(l,v) cos\theta_0 d\omega$$
		\begin{itemize}
			\item $\phi$ is the hemispherical in surface normal half
			\item $\theta_0$ is the angel between camera view and surface normal
			\item $\omega$ is the space angle
		\end{itemize}
		\item Basically, $R(l)$ is \textbf{the sum of the (directional) energy} of all output light in hemisphere.
		\item The output energy \textbf{should be equal or less than} the input energy so:
		$$R(l)\leq 1$$
	\end{itemize}
\end{itemize}
\subsection{How to calculate BRDF}
\subsubsection{From Lambertian Model}
\begin{itemize}
	\item \textbf{Lambertian Model}: Only Diffuse Color, No Specular Color. All output direction are the Same.
	\item In this model, we assume the output energy is part of input energy. So We can build this equation:
	$$R(l)=C_{diff}$$
	So:
	$$C_{diff}=R(l)=\int_\phi f(l,v) cos\theta_0 d\omega$$
	We know $f(l,v)$ and $C_{diff}$ are both constant number:
	$$f(l,v) \cdot \int_\phi cos\theta_0 d\omega=C_{diff}$$
	$$f(l,v)=\frac{C_{diff}}{\pi}$$
\end{itemize}
\subsubsection{A little bit harder: Phong Model}
\begin{itemize}
	\item We assume the ambient light equal to 0 then the shading equation is:
	$$L_0=(cos\theta_i * C_{diff} + (cos\alpha_r)^{spec}*C_{spec})\times B_L$$
	\begin{itemize}
		\item first part is \textbf{Lambertian model}
		\item $\alpha_r$ is the angel between reflection vector and camera vector
	\end{itemize}
	\item And we have shading equation in BRDF format:
	$$L_0(v)= f(l,v)\times E_l cos\theta_{ik}$$
	\item So we have a basic equation for $f(l,v)$ that:
	$$f(l,v)=\frac{C_{diff}}{\pi}+\frac{(cos\alpha_r)^{spec}*C_{spec}}{\pi * cos\theta_i}$$
	\item Notices that: If we need to normalize this equation, let $R_{spec}(l) = C_{spec}$
	\item First: When $\theta_i=\frac{\pi}{2}$, $f(l,v)=+\inf$, which is implausible, so we times $cos\theta_i$ and a constant $k$:
	$$f_{spec}(l,v)=k * \frac{(cos\alpha_r)^{spec}*C_{spec}}{\pi}$$
	\item Second:
	$$C_{spec}=R(l)=\int_\phi k*f_{spec}(l,v) cos\theta_0 d\omega=k*C_{spec}/\pi * \int_\phi(cos\alpha_r)^{spec} cos\theta_0d\omega$$
	\item It's very hard to do this calculation, by experience we can get:
	$$k=\frac{spec+2}{2}$$
	\item So in Phong Model:
	$$f(l,v)=\frac{C_{diff}}{\pi} + \frac{(spec+2)C_{spec}*(cos\alpha_r)^{spec}}{2\pi}$$
\end{itemize}
\subsubsection{A little bit more harder: Blinn-Phong Model}
\begin{itemize}
	\item We define $\vec{H}$ is the Halfway-Vector(Normalize the vector of the middle point) of input vector and camera vector.
	$$H=\frac{L+V}{|L+V|}$$ 
	\item Shading equation:
	$$L_0=(cos\theta_i * C_{diff} + (cos\beta)^{spec}*C_{spec})\times B_L$$
	$\beta$ is the angel between $H$ and surface normal vector.
	\item Follow the step in Phong Model:
	$$k=\frac{spec+8}{8}$$
	\item And:
	$$f(l,v)=\frac{C_{diff}}{\pi} + \frac{(spec+8)C_{spec}*(cos\beta)^{spec}}{8\pi}$$
\end{itemize}
\subsubsection{Microfacet Model in \href{https://disney-animation.s3.amazonaws.com/library/s2012_pbs_disney_brdf_notes_v2.pdf}{Disney Paper}}
\begin{itemize}
	\item Equation First:
	$$f(l,v)=diffuse + \frac{D(\theta_h)F(\theta_d)G(\theta_l,\theta_v)}{4cos\theta_l cos\theta_v}$$
	\item Microfacet Model: The surface is an aggregate of many microfacet, each microfacet have different normal and you can only see part of the microfacet, and some microfacet might be blocked by others.
	\item How many microfacets you can see is define by $D(\theta_h)$
	\item How many microfacets is blocked by other microfacets is define by $G(\theta_l,\theta_v)$
	\item The fraction of reflaction energy in the total input energy is define by $F(\theta_d)$ 
	\item $\frac{1}{4cos\theta_l cos\theta_v}$ is a normalize factor. 
\end{itemize}
\subsubsection{BRDF With Physics Based Render}
\begin{itemize}
	\item In Disney's paper Section 5.3~5.6, it present how \textbf{roughness} can affect diffuse function and G function.
	\item Diffuse Function:
	$$diffuse=\frac{baseColor}{\pi}(1+(F_{D90}-1)(1-cos\theta_l)^5)(1+(F_{D90}-1)(1-cos\theta_v)^5)$$
	$$F_{D90}=0.5+2*cos\theta^2_d*roughness$$
	\item D Function:
	$$D_GTR=\frac{c}{(\alpha^2cos^2\theta_h +sin^2\theta_h)^\gamma}$$
	$$\alpha=roughness^2$$
	\item F Function:
	$$F_{Schlick}=F_0 + (1-F_0)(1-cos\theta_d)^5$$
	\item G Function: Using GGX Function\\
	Reference: \textit{Microfacet Models for Refraction through Rough Surfaces }
	$$\alpha_g=(0.5+roughness/2)^2$$
\end{itemize}
\section{Next Step:}
\begin{itemize}
	\item Build the BRDF shading function in unity.
	\item Find a better diffuse,D,F,G Function
	\item Put some new variable into diffuse,D,F,G
\end{itemize}
\newpage
\section{finalEquation}
$$
\begin{aligned}
f_{disneyBRDF}(\vec{L},\vec{N},\vec{V})&=(1-metallic)(\frac{basecolor}{\pi}(f_d*(1-subsurface)+f_{ss}*subsurface)+f_{sh})\\
&+\frac{F_s*G_s*D_s}{4*\vec{N}\cdot\vec{L}*\vec{N}\cdot\vec{V}}+\frac{clearcoat}{4}*\frac{F_c*G_c*D_c}{4*\vec{N}\cdot\vec{L}*\vec{N}\cdot\vec{V}}
\end{aligned}
$$
$$
\begin{aligned}
f_d&=(1+(F_{D90}-1)(1-\vec{N}\cdot\vec{L})^5)(1+(F_{D90}-1)(1-\vec{N}\cdot\vec{V})^5)\\
F_{D90}&=0.5+2*\cos^2(\vec{N}\cdot\vec{H})*roughness
\end{aligned}
$$
$$
\begin{aligned}
f_{ss}&=1.25(((1+(F_{ss90}-1)(1-\vec{N}\cdot\vec{L})^5)(1+(F_{ss90}-1)(1-\vec{N}\cdot\vec{V})^5))(\frac{1}{\vec{N}\cdot\vec{L}+\vec{N}\cdot\vec{V}}-0.5)+0.5)\\
F_{ss90}&=\cos^2(\vec{N}\cdot\vec{H})*roughness
\end{aligned}
$$
$$
\begin{aligned}
f_{sh}&=(white*(1-sheenTint)+\frac{baseColor}{lum(baseColor)}*sheenTint)*sheen*(1-\vec{N}\cdot\vec{H})^5\\
C_{tint}&=\frac{baseColor}{lum(baseColor)}
\end{aligned}
$$
$$
\begin{aligned}
F_{s}&=C_{s}+(1-C_{s})(1-\vec{N}\cdot\vec{H})^5\\
C_{s}&=(1-metallic)*0.08specular((1-specularTint)white+specularTint\frac{baseColor}{lum(baseColor)})+metallic*baseColor
\end{aligned}
$$
$$
\begin{aligned}
G_{s}&=\frac{1}{\vec{N}\cdot\vec{V}+\sqrt{\alpha_{G}^2+(\vec{N}\cdot\vec{V})^2-\alpha_{G}(\vec{N}\cdot\vec{V})}}\\
\alpha_{G}&=\frac{1+roughness}{2}^2
\end{aligned}
$$
$$
\begin{aligned}
D_{s}&=\frac{1}{\pi*roughness^4*((\frac{\vec{H}\cdot\vec{X}}{roughness^2/a}+\frac{\vec{H}\cdot\vec{Y}}{roughness^2*a})^2+(\vec{N}\cdot\vec{H})^2)^2}\\
a&=\sqrt{1-0.9*anisotropic}
\end{aligned}
$$
$$
F_{c}=0.04+0.96*(1-\vec{V}\cdot\vec{H})^5
$$
$$
D_{c}=\frac{(0.1-0.09clearCoatGloss)^2-1}{2\pi\ln(0.1-0.09clearCoatGloss)*((0.1-0.09clearCoatGloss)^2*(\vec{N}\cdot\vec{V})^2+(1-(\vec{N}\cdot\vec{H})^2))}
$$
$$
G_{c}=\frac{1}{\vec{N}\cdot\vec{V}+\sqrt{(0.5+roughness*0.5)^4+({\vec{N}\cdot\vec{V})^4-(0.5+roughness*0.5)^2*({\vec{N}\cdot\vec{V})^2}}}}
$$
\newpage
\subsection{FullyExpent}
$
f_{disneyBRDF}(\vec{L},\vec{N},\vec{V})=(1-metallic)(\frac{basecolor}{\pi}(((1+((0.5+2*\cos^2(\vec{N}\cdot\vec{H})*roughness)-1)(1-\vec{N}\cdot\vec{L})^5)(1+((0.5+2*\cos^2(\vec{N}\cdot\vec{H})*roughness)-1)(1-\vec{N}\cdot\vec{V})^5))*(1-subsurface)+(1.25(((1+(\cos^2(\vec{N}\cdot\vec{H})*roughness-1)(1-\vec{N}\cdot\vec{L})^5)(1+(\cos^2(\vec{N}\cdot\vec{H})*roughness-1)(1-\vec{N}\cdot\vec{V})^5))(\frac{1}{\vec{N}\cdot\vec{L}+\vec{N}\cdot\vec{V}}-0.5)+0.5))*subsurface)+((white*(1-sheenTint)+\frac{baseColor}{lum(baseColor)}*sheenTint)*sheen*(1-\vec{N}\cdot\vec{H})^5))+(1-metallic)*0.08specular((1-specularTint)white+specularTint\frac{baseColor}{lum(baseColor)})+metallic*baseColor+(1-(1-metallic)*0.08specular((1-specularTint)white+specularTint\frac{baseColor}{lum(baseColor)})+metallic*baseColor)(1-\vec{N}\cdot\vec{H})^5*\frac{1}{\vec{N}\cdot\vec{V}+\sqrt{\frac{1+roughness}{2}^4+(\vec{N}\cdot\vec{V})^2-\frac{1+roughness}{2}^2(\vec{N}\cdot\vec{V})}}*(\frac{1}{\pi*roughness^4*((\frac{\vec{H}\cdot\vec{X}}{roughness^2\sqrt{1-0.9*anisotropic}}+\frac{\vec{H}\cdot\vec{Y}}{roughness^2\sqrt{1-0.9*anisotropic}})^2+(\vec{N}\cdot\vec{H})^2)^2})/(4*\vec{N}\cdot\vec{L}*\vec{N}\cdot\vec{V})+\frac{clearcoat}{4}*(0.04+0.96*(1-\vec{V}\cdot\vec{H})^5)/(\vec{N}\cdot\vec{V}+\sqrt{(0.5+roughness*0.5)^4+({\vec{N}\cdot\vec{V})^4-(0.5+roughness*0.5)^2*({\vec{N}\cdot\vec{V})^2}}})*((0.1-0.09clearCoatGloss)^2-1)/(2\pi\ln(0.1-0.09clearCoatGloss)*((0.1-0.09clearCoatGloss)^2*(\vec{N}\cdot\vec{V})^2+(1-(\vec{N}\cdot\vec{H})^2))))/(4*\vec{N}\cdot\vec{L}*\vec{N}\cdot\vec{V})
$
\end{document}